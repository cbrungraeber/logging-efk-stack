# forward Input Plugin
# The in_forward Input plugin listens to a TCP socket to receive the event stream.
# It also listens to an UDP socket to receive heartbeat messages.
# This plugin is mainly used to receive event logs from other Fluentd instances,
# the fluent-cat command, or client libraries.
# This is by far the most efficient way to retrieve the records.
# https://docs.fluentd.org/v1.0/articles/in_forward
<source>
  @type forward
  port 24224
  bind 0.0.0.0
</source>

# HTTP Input Plugin
# The in_http Input plugin allows you to send events through HTTP requests.
# Using this plugin, you can trivially launch a REST endpoint to gather data.
# https://docs.fluentd.org/v1.0/articles/in_http
<source>
  @type http
  port 9880
  bind 0.0.0.0
  body_size_limit 32m
  keepalive_timeout 10s
</source>

# stdout Filter Plugin
# The filter_stdout filter plugin prints events to stdout (or logs if launched with daemon mode).
# This filter plugin is useful for debugging purposes.
# https://docs.fluentd.org/v1.0/articles/filter_stdout
<filter nginx>
  @type stdout
</filter>

# json Parser Plugin
# The json parser plugin parses JSON logs. One JSON map per line.
# https://docs.fluentd.org/v1.0/articles/parser_json
# https://docs.fluentd.org/v1.0/articles/filter_parser
<filter application.**>
  @type parser
  key_name log
  # Keep original key-value pair in parsed result
  reserve_data true
  remove_key_name_field true

  <parse>
    @type json
    time_key @timestamp
    # Specify time format for event time for rfc5424 protocol.
    # https://docs.fluentd.org/v1.0/articles/parser_syslog#time_format
    time_format %Y-%m-%dT%H:%M:%S.%L%z
  </parse>
</filter>

# rewrite_tag_filter Output Plugin
# The out_rewrite_tag_filter Output plugin provides a rule-based mechanism for rewriting tags.
# https://docs.fluentd.org/v1.0/articles/out_rewrite_tag_filter#%3Crule%3E-section
<match nginx>
  @type rewrite_tag_filter
  <rule>
    key source
    pattern /^stdout$/,
    tag ${tag}.access
  </rule>
  <rule>
    key source
    pattern /^stderr$/,
    tag ${tag}.error
  </rule>
</match>

# nginx Parser Plugin
# The nginx parser plugin parses default nginx logs.
# https://docs.fluentd.org/v1.0/articles/parser_nginx
<filter nginx.access>
  @type parser
  key_name log

  <parse>
    @type nginx
  </parse>
</filter>

# GeoIP Filter Plugin
# The filter_geoip Filter plugin adds geographic location information to logs
# using the Maxmind GeoIP databases.
# https://docs.fluentd.org/v1.0/articles/filter_geoip
<filter nginx.access>
  @type geoip
  @log_level debug

  # Specify one or more geoip lookup field which has ip address (default: host)
  # in the case of accessing nested value, delimit keys by dot like 'host.ip'.
  geoip_lookup_keys  remote

  # Specify downloaded geoip2 database since it offers more precise entries.
  geoip2_database   "/GeoLite2-City.mmdb"
  # Specify backend library (geoip2_c, geoip, geoip2_compat)
  backend_library   geoip2_c

  # Set adding field with placeholder (more than one settings are required.)
  # Changing field order in <record> like following:
  <record>
    latitude        ${location.latitude["remote"]}
    longitude       ${location.longitude["remote"]}

    # Geo-point expressed as an object, with lat and lon keys.
    # https://www.elastic.co/guide/en/elasticsearch/reference/6.x/geo-point.html
    location        '{"lat":${location.latitude["remote"]},"lon":${location.longitude["remote"]}}'
    # coordinates     '[${location.longitude["remote"]},${location.latitude["remote"]}]'

    country         ${country.iso_code["remote"]}
    country_name    ${country.names.en["remote"]}
    postal_code     ${postal.code["remote"]}
    city            ${city.names.en["remote"]}
    region_code     ${subdivisions.0.iso_code["remote"]}
    region_name     ${subdivisions.0.names.en["remote"]}
  </record>

  # To avoid get stacktrace error with `[null, null]` array for elasticsearch.
  skip_adding_null_record  true
</filter>

<filter nginx.error>
  @type parser
  key_name log

  <parse>
    @type multiline
    format_firstline /^\d{4}/\d{2}/\d{2} \d{2}:\d{2}:\d{2} \[\w+\] (?<pid>\d+).(?<tid>\d+): /
    format1 /^(?<time>\d{4}/\d{2}/\d{2} \d{2}:\d{2}:\d{2}) \[(?<log_level>\w+)\] (?<pid>\d+).(?<tid>\d+): (?<message>.*)/
  </parse>
</filter>

<match **>
  @type copy

  <store>
    @type elasticsearch
    host elasticsearch
    port 9200
    logstash_format true
    logstash_prefix fluentd
    include_tag_key true
    tag_key @log_name

    # Specify an index template in order to update the mapping for location/geo_point
    # https://github.com/uken/fluent-plugin-elasticsearch#template_file
    template_name fluentd
    template_file /fluentd.json

    <buffer>
      flush_interval 10s
    </buffer>
  </store>
  <store>
    @type stdout
  </store>
</match>